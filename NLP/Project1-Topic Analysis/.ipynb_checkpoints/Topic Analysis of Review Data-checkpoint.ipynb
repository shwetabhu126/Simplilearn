{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Analysis of Review Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DESCRIPTION\n",
    "\n",
    "Help a leading mobile brand understand the voice of the customer by analyzing the reviews of their product on Amazon and the topics that customers are talking about. You will perform topic modeling on specific parts of speech. You’ll finally interpret the emerging topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem Statement: \n",
    "\n",
    "A popular mobile phone brand, Lenovo has launched their budget smartphone in the Indian market. The client wants to understand the VOC (voice of the customer) on the product. This will be useful to not just evaluate the current product, but to also get some direction for developing the product pipeline. The client is particularly interested in the different aspects that customers care about. Product reviews by customers on a leading e-commerce site should provide a good view."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Domain:** Amazon reviews for a leading phone brand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis to be done: \n",
    "POS tagging, topic modeling using LDA, and topic interpretation\n",
    "\n",
    "**Dataset:** ‘K8 Reviews v0.2.csv’\n",
    "\n",
    "**Sentiment:** The sentiment against the review (4,5 star reviews are positive, 1,2 are negative)\n",
    "\n",
    "**Reviews:** The main text of the review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps to perform:\n",
    "\n",
    "Discover the topics in the reviews and present it to business in a consumable format. Employ techniques in syntactic processing and topic modeling.\n",
    "\n",
    "Perform specific cleanup, POS tagging, and restricting to relevant POS tags, then, perform topic modeling using LDA. Finally, give business-friendly names to the topics and make a table for business."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tasks: \n",
    "\n",
    "1. Read the .csv file using Pandas. Take a look at the top few records.\n",
    "\n",
    "2. Normalize casings for the review text and extract the text into a list for easier manipulation.\n",
    "\n",
    "3. Tokenize the reviews using NLTKs word_tokenize function.\n",
    "\n",
    "4. Perform parts-of-speech tagging on each sentence using the NLTK POS tagger.\n",
    "\n",
    "5. For the topic model, we should  want to include only nouns.\n",
    "\n",
    "  - Find out all the POS tags that correspond to nouns.\n",
    "\n",
    "  - Limit the data to only terms with these tags.\n",
    "\n",
    "6. Lemmatize. \n",
    "\n",
    "  - Different forms of the terms need to be treated as one.\n",
    "\n",
    "  - No need to provide POS tag to lemmatizer for now.\n",
    "\n",
    "7. Remove stopwords and punctuation (if there are any). \n",
    "\n",
    "8. Create a topic model using LDA on the cleaned up data with 12 topics.\n",
    "\n",
    "  - Print out the top terms for each topic.\n",
    "\n",
    "  - What is the coherence of the model with the c_v metric?\n",
    "\n",
    "9. Analyze the topics through the business lens.\n",
    "\n",
    "  - Determine which of the topics can be combined.\n",
    "\n",
    "10. Create topic model using LDA with what you think is the optimal number of topics\n",
    "\n",
    "  - What is the coherence of the model?\n",
    "\n",
    "11. The business should  be able to interpret the topics.\n",
    "\n",
    "  - Name each of the identified topics.\n",
    "\n",
    "  - Create a table with the topic name and the top 10 terms in each to present to the  business."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import gensim\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('K8 Reviews v0.2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Normalizing the casing to lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review_cleaned'] = data['review'].apply(lambda review: review.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Tokenize the reviews using NLTKs word_tokenize function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = data['review_cleaned']\n",
    "reviews = [nltk.word_tokenize(review) for review in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(reviews[:5], compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Perform parts-of-speech tagging on each document using the NLTK POS tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "review_pos_tags = [nltk.pos_tag(doc) for doc in reviews]\n",
    "pprint(review_pos_tags[:5], compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Including only nouns for building the Topic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_nouns = [[token for token, pos in doc if pos.startswith('NN')] for doc in review_pos_tags]\n",
    "pprint(review_nouns[:5], compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "review_lemmatized = [[nltk.stem.WordNetLemmatizer().lemmatize(token) for token in doc] for doc in review_nouns]\n",
    "pprint(review_lemmatized[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Remove stopwords and punctuation (if there are any)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "review_no_sw = [[token for token in doc if token not in nltk.corpus.stopwords.words('english') \n",
    "                 and token.isalpha()] \n",
    "                for doc in review_lemmatized]\n",
    "pprint(review_no_sw[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Create a topic model using LDA on the cleaned up data with 12 topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Dictionary - association word to numeric id\n",
    "dictionary = corpora.Dictionary(review_no_sw)\n",
    "# Transform the collection of texts to a numerical form\n",
    "corpus = [dictionary.doc2bow(text) for text in review_no_sw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOPICS = 6\n",
    "lda_model = gensim.models.LdaModel(corpus=corpus, num_topics=NUM_TOPICS, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LDA Model:\")\n",
    " \n",
    "for idx in range(NUM_TOPICS):\n",
    "    # Print the first 10 most representative topics\n",
    "    pprint(\"Topic #{}: {}\".format(idx, lda_model.print_topic(idx, 10)), compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Coherence Score\n",
    "coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, texts=review_no_sw, dictionary=dictionary, coherence='c_v')\n",
    "\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('Coherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1 Print out the top terms for each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2 coherence of the model with the c_v metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Analyze the topics through the business lens - Determine which of the topics can be combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stop_words = ['phone', 'problem', 'issue', 'product', 'mobile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Create topic model using LDA with what you think is the optimal number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.1 Coherence of the optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Business interpretation of the identified topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.1. Table with the topic names and the top 10 terms in each to present to the business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
